StudentCareerCounsellor – Integration Plan for id3.js, algo, and trainingdata.txt

Scope
- Connect backend ID3 decision tree (backend/ml/id3.js) with a REST endpoint.
- Load and train from trainingdata.txt (and/or existing CSVs in AttributesData/...).
- Wire the client UI (client/src/Components/RecommendationForm.jsx) to the backend.
- Provide a clean seam to plug additional algorithms via an algo module.

Directory/Files
- backend/ml/id3.js: Exports ID3DecisionTree with trainModel(datasetKey, rows) and predict(userType, features).
- backend/server.js: Express API host; add training loader and POST /api/recommendations/generate.
- backend/ml/trainingdata.txt: Plain-text dataset you provide (see Formats below). Place here.
- AttributesData/**: Optional extra CSVs already present; can be used to enrich training.
- client/src/Components/RecommendationForm.jsx: Calls /api/recommendations/generate.

Backend – Steps
1) Ensure id3.js public API
   - Required methods:
     - trainModel(datasetKey: string, rows: Array<Record<string,string>>): void
     - predict(userType: 'see' | 'plusTwo' | 'bachelor', features: Record<string,string>): { prediction: string, confidence?: number, reasoning?: string }
   - If not present, implement these wrappers in id3.js so server.js stays simple.

2) Place trainingdata.txt
   - Path: backend/ml/trainingdata.txt
   - Formats supported (pick one and keep consistent):
     a) CSV header row, comma-delimited
        Example header for SEE flow:
        SEE_GPA,SEE_Science_GPA,SEE_Math_GPA,Fee,Hostel,Transportation,Future_Career,ECA,Scholarship,ScienceLabs,Infrastructure,BestCollege
     b) JSON Lines (one JSON per line)
        {"SEE_GPA":">2.8","SEE_Science_GPA":">2.4", ... }
   - If using CSV, make sure commas inside values are quoted.

3) Normalize UI -> Model feature mapping
   - RecommendationForm uses user-friendly labels; map them to model categories:
     SEE
     - seeGpa: "High (>2.8)" -> ">2.8"; "Medium (2.4-2.8)" -> "2.0-2.8"; "Low (<2.4)" -> "<2.0" or "<2.4" (pick one and match training)
     - seeScienceGpa: "High (>2.4)" -> ">2.4"; "Medium (2.0-2.4)" -> "2.0-2.4"; "Low (<2.0)" -> "<2.0"
     - seeMathGpa: same buckets as science GPA
     - feePreference: "Low" -> "<2 lakhs"; "Medium" -> "2-3 lakhs"; "High" -> ">3 lakhs"
     - hostel: "Yes"/"No" -> "Yes"/"No"
     - transportation: "Available"/"Not Available" -> "Yes"/"No"
     - futureCareer: map to training values, e.g. Science/Arts/Commerce/Technical -> IT/Medical/Arts/etc. Decide final set and keep consistent.
     - eca: user picks activity; normalize to performance label expected by training (e.g., Good/Average/Bad). You can derive: sports/volunteering -> Good; none -> Bad; else -> Average.
     - scholarship: "Yes"/"No" -> "Available"/"Not Available"
     - scienceLabs, infrastructure: map Excellent/Good/Average/Poor -> Good/Average/Bad or keep the 4-tier scale, but ensure training matches.
   - Do equivalent mappings for plusTwo and bachelor flows once those datasets exist.

4) Implement training loader in backend/server.js
   - On startup:
     - Read backend/ml/trainingdata.txt
     - Parse according to chosen format (CSV or JSONL)
     - Call id3Model.trainModel('see', parsedRows)
   - Optional: Also parse AttributesData/collegeData/** CSVs and merge or train additional dataset keys (e.g., 'plusTwo', 'bachelor') later.

5) Add/complete the API endpoint
   - Route: POST /api/recommendations/generate
   - Body: { userType: 'see' | 'plusTwo' | 'bachelor', academicInfo: {...}, preferences: {...} }
   - Steps inside handler:
     - Derive features = normalize({ ...academicInfo, ...preferences }) using the mapping above.
     - const result = id3Model.predict(userType, features)
     - Return { recommendations: [ { prediction: result.prediction, confidence: result.confidence ?? 0.7, reasoning: result.reasoning ?? "Predicted by ID3" } ] }
   - Keep the shape identical to the UI expectation (RecommendationForm consumes recommendations[] with prediction, confidence, reasoning).

6) Environment/config
   - Expose PORT via process.env.PORT (already used) and CORS enabled.
   - In development, run backend at http://localhost:3000 and client at Vite default http://localhost:5173.
   - Add a proxy in client/vite.config.js or use VITE_API_URL to avoid CORS headaches.

Client/UI – Steps
1) Configure API base URL
   - Preferred: Add VITE_API_URL to client/.env (e.g., VITE_API_URL=http://localhost:3000)
   - Update RecommendationForm fetch to use `${import.meta.env.VITE_API_URL}/api/recommendations/generate`

2) Map UI selections to model categories before POST
   - Implement a small normalizeForApi(userType, formData) helper that returns the mapped features as listed in Backend step 3. Keep in a utils file, reuse on both server and client if you create a shared mapping.

3) Handle API response
   - The current component expects { recommendations: Array<{ prediction, confidence, reasoning }> } and already renders them; no change needed if response matches.
   - Optionally add error UI if the response is non-200.

4) Optional UX improvements
   - Disable Next until required fields selected.
   - Add tooltips explaining buckets (e.g., why "High (>2.8)" maps to ">2.8").

algo Module – Pluggable Strategy
- Create backend/ml/algo/index.js (or similar) with a registry:
  module.exports = {
    selectEngine(userType) { return 'id3'; },
    engines: { id3: id3Model /* or factory */, /* future: randomForest, svm, llm */ }
  }
- In server.js, call algo.selectEngine(userType) and route to the chosen engine.
- This lets you keep id3.js as the default while allowing easy upgrades.

Testing Checklist
- Unit: Given a fixed trainingdata.txt, ensure predict returns deterministic result for a known feature vector.
- API: POST /api/recommendations/generate with a sample body returns 200 and shape { recommendations: [...] }.
- UI: Full flow submit shows one or more recommendation cards, with confidence badge.

Deployment Notes
- Ensure trainingdata.txt is bundled/deployed to server along with backend/ml/id3.js.
- For production, set VITE_API_URL to the deployed backend URL and rebuild the client.
- Consider caching the trained model in memory and reloading on file change or via an admin endpoint to retrain without restart.

Example Pseudocode – server.js additions (for guidance only)
- Startup training
  const fs = require('fs');
  const path = require('path');
  const dataPath = path.join(__dirname, 'ml', 'trainingdata.txt');
  const raw = fs.readFileSync(dataPath, 'utf-8');
  const rows = parseCsv(raw); // or parseJsonLines(raw)
  id3Model.trainModel('see', rows);

- Endpoint
  app.post('/api/recommendations/generate', (req, res) => {
    const { userType, academicInfo = {}, preferences = {} } = req.body || {};
    const features = normalizeForModel(userType, { ...academicInfo, ...preferences });
    const result = id3Model.predict(userType, features);
    res.json({ recommendations: [ { prediction: result.prediction, confidence: result.confidence ?? 0.7, reasoning: result.reasoning ?? 'Predicted by ID3' } ] });
  });

Where to change UI
- client/src/Components/RecommendationForm.jsx
  - Change fetch URL to use VITE_API_URL.
  - Add normalizeForApi before POST or rely on server normalization if you prefer single-source mapping.

That’s it. Provide trainingdata.txt in the specified format, and follow the mappings to keep labels consistent across UI, training, and inference.
